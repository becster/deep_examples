{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Implementation for the dataset for the competition https://www.kaggle.com/c/dogs-vs-cats\n",
    "# On image cat-dog classification\n",
    "# Inspared on: https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d\n",
    "\n",
    "import  numpy  as np\n",
    "import  matplotlib.pyplot  as plt\n",
    "import h5py\n",
    "import scipy\n",
    "import os, os.path\n",
    "import keras\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 150\n",
    "batch_size = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_size, img_size)\n",
    "else:\n",
    "    input_shape = (img_size, img_size, 3)\n",
    "\n",
    "#To generate the train_datagen from flow_from_directory, the dataset must be in a directory with two subdirectories.\n",
    "#Example: Train path: dataset/all/train\n",
    "#         Train subdirectories:  1) dataset/all/train/cat  2) dataset/all/train/dog\n",
    "\n",
    "train_dir = 'dataset/all/train'\n",
    "validation_dir = 'dataset/all/validation/'\n",
    "DIR = 'dataset/all/train'\n",
    "\n",
    "numImages = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 3000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Example using dataFlow from Image\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 295s 2s/step - loss: 0.6944 - acc: 0.6567 - val_loss: 0.6998 - val_acc: 0.6667\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 247s 2s/step - loss: 0.6269 - acc: 0.6655 - val_loss: 0.5987 - val_acc: 0.6893\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 242s 2s/step - loss: 0.5840 - acc: 0.7003 - val_loss: 0.5581 - val_acc: 0.7073\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 243s 2s/step - loss: 0.5755 - acc: 0.7146 - val_loss: 0.5422 - val_acc: 0.7330\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 241s 2s/step - loss: 0.5417 - acc: 0.7377 - val_loss: 0.5476 - val_acc: 0.7453\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 241s 2s/step - loss: 0.5351 - acc: 0.7385 - val_loss: 0.5146 - val_acc: 0.7570\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 242s 2s/step - loss: 0.5171 - acc: 0.7505 - val_loss: 0.4994 - val_acc: 0.7647\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 1589s 13s/step - loss: 0.4901 - acc: 0.7678 - val_loss: 0.4886 - val_acc: 0.7693\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 283s 2s/step - loss: 0.4960 - acc: 0.7656 - val_loss: 0.4769 - val_acc: 0.7807\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 280s 2s/step - loss: 0.4685 - acc: 0.7833 - val_loss: 0.4691 - val_acc: 0.7770\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 293s 2s/step - loss: 0.4656 - acc: 0.7757 - val_loss: 0.4569 - val_acc: 0.7953\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 317s 3s/step - loss: 0.4542 - acc: 0.7948 - val_loss: 0.4488 - val_acc: 0.7930\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 286s 2s/step - loss: 0.4385 - acc: 0.7971 - val_loss: 0.5260 - val_acc: 0.7867\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.4349 - acc: 0.7984 - val_loss: 0.4507 - val_acc: 0.7930\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 255s 2s/step - loss: 0.4329 - acc: 0.8125 - val_loss: 0.4555 - val_acc: 0.8007\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 265s 2s/step - loss: 0.4378 - acc: 0.8036 - val_loss: 0.6092 - val_acc: 0.7990\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 263s 2s/step - loss: 0.4238 - acc: 0.8133 - val_loss: 0.4465 - val_acc: 0.7990\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 259s 2s/step - loss: 0.4155 - acc: 0.8138 - val_loss: 0.4359 - val_acc: 0.8003\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 288s 2s/step - loss: 0.4173 - acc: 0.8158 - val_loss: 0.5177 - val_acc: 0.7630\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 260s 2s/step - loss: 0.4014 - acc: 0.8238 - val_loss: 0.5542 - val_acc: 0.7313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2190db1bcc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = 4000\n",
    "n_validation = 2000\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('catDog_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x000002190DB1BCC0>\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(model.history)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
